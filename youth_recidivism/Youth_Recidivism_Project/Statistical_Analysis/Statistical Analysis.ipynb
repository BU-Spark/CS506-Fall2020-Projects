{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jieba import analyse\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_pickle('../../Youth_Recidivism_Project/Dataset/train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = file['total_notes']\n",
    "yes = file['YES'].to_numpy()\n",
    "new_data = pd.DataFrame({'yes':yes})\n",
    "new_data['comments'] = comments\n",
    "new_data['mid'] = file['MID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"../../Youth_Recidivism_Project/Dataset/comment_yes.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/98/nz1_948x12d7bjtk2jwm41cr0000gn/T/jieba.cache\n",
      "Loading model cost 0.598 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "new_data_0 = []\n",
    "new_data_1 = []\n",
    "new_data_0_np = []\n",
    "new_data_1_np = []\n",
    "tfidf = analyse.extract_tags\n",
    "for i in range(new_data.shape[0]):\n",
    "    if new_data.iloc[i,1] != new_data.iloc[i,1]:\n",
    "        if new_data.iloc[i,0] < 0.5:\n",
    "            new_data_0.append([])\n",
    "        else:\n",
    "            new_data_1.append([])\n",
    "    else:\n",
    "        if new_data.iloc[i,0] < 0.5:\n",
    "            new_data_0.append(tfidf(new_data.iloc[i,1], topK = 10))\n",
    "            new_data_0_np += tfidf(new_data.iloc[i,1], topK = 10)\n",
    "        else:\n",
    "            new_data_1.append(tfidf(new_data.iloc[i,1], topK = 10))\n",
    "            new_data_1_np += tfidf(new_data.iloc[i,1], topK = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_0_dic = {}\n",
    "new_data_1_dic = {}\n",
    "for i in new_data_0_np:\n",
    "    if i not in new_data_0_dic:\n",
    "        new_data_0_dic[i] = 1\n",
    "    else:\n",
    "        new_data_0_dic[i] += 1\n",
    "for i in new_data_1_np:\n",
    "    if i not in new_data_1_dic:\n",
    "        new_data_1_dic[i] = 1\n",
    "    else:\n",
    "        new_data_1_dic[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_1_dic = dict(sorted(new_data_1_dic.items(), key=lambda item: item[1], reverse = True))\n",
    "new_data_0_dic = dict(sorted(new_data_0_dic.items(), key=lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en',disable=['parser', 'ner'])\n",
    "def lemmatization(nlp, texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    doc = nlp(\" \".join(texts))\n",
    "    texts_out += ([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lemmatization(nlp, list(new_data_1_dic))\n",
    "y = lemmatization(nlp, list(new_data_0_dic))\n",
    "new_data_1_dic = {k: new_data_1_dic[k] for k in list(new_data_1_dic) if k in x}\n",
    "new_data_0_dic = {k : new_data_0_dic[k] for k in list(new_data_0_dic) if k in y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_1_dic = {k: new_data_1_dic[k] for k in list(new_data_1_dic)[:50]}\n",
    "new_data_0_dic = {k: new_data_0_dic[k] for k in list(new_data_0_dic)[:50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'her': 13070, 'home': 10104, 'today': 9247, 'school': 7040, 'mother': 6536, 'will': 6239, 'up': 5891, 'meeting': 5206, 'program': 4859, 'writer': 4791, 'had': 4782, 'check': 4544, 'client': 4255, 'well': 4147, 'office': 3794, 'visit': 3332, 'would': 3203, 'informed': 3196, 'doing': 2904, 'call': 2633, 'youth': 2620, 'work': 2524, 'going': 2417, 'contacted': 2308, 'court': 2083, 'mom': 2036, 'out': 1987, 'house': 1977, 'time': 1956, 'know': 1910, 'phone': 1900, 'see': 1871, 'case': 1776, 'let': 1727, 'pass': 1701, 'also': 1692, 'over': 1633, 'back': 1525, 'regarding': 1490, 'go': 1473, 'get': 1470, 'date': 1447, 'day': 1425, 'family': 1405, 'no': 1349, 'foster': 1343, 'clinician': 1341, 'meet': 1328, 'discuss': 1303, 'able': 1281}\n",
      "{'home': 7909, 'her': 6861, 'today': 6457, 'spoke': 5418, 'will': 5414, 'mother': 5341, 'school': 4390, 'up': 4207, 'program': 4078, 'meeting': 3776, 'check': 3562, 'client': 3459, 'writer': 3253, 'well': 3216, 'visit': 2966, 'me': 2840, 'would': 2671, 'informed': 2668, 'office': 2440, 'call': 2068, 'court': 1964, 'work': 1941, 'youth': 1925, 'time': 1832, 'case': 1744, 'text': 1616, 'out': 1585, 'house': 1548, 'date': 1434, 'see': 1416, 'know': 1411, 'phone': 1403, 'no': 1273, 'let': 1268, 'pass': 1260, 'back': 1244, 'also': 1229, 'mom': 1216, 'week': 1158, 'day': 1114, 'clinician': 1087, 'meet': 1085, 'get': 1055, 'message': 1038, 'family': 1036, 'go': 1022, 'staff': 1021, 'could': 1019, 'tomorrow': 1010, 'job': 982}\n"
     ]
    }
   ],
   "source": [
    "print(new_data_1_dic)\n",
    "print(new_data_0_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foster', 'over', 'had', 'able', 'doing', 'discuss', 'going', 'contacted', 'regarding'}\n",
      "{'week', 'job', 'text', 'message', 'spoke', 'could', 'staff', 'tomorrow', 'me'}\n"
     ]
    }
   ],
   "source": [
    "print(set(new_data_1_dic) - set(new_data_0_dic))\n",
    "print(set(new_data_0_dic) - set(new_data_1_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_0 = []\n",
    "average_1 = []\n",
    "for i in range(new_data.shape[0]):\n",
    "    if new_data.iloc[i,1] != new_data.iloc[i,1]:\n",
    "        average_0 = average_0\n",
    "    else:\n",
    "        if new_data.iloc[i,0] < 0.5:\n",
    "            average_0.append(len(new_data.iloc[i,1].split(\" \")))\n",
    "        else:\n",
    "            average_1.append(len(new_data.iloc[i,1].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66072\n",
      "80209\n",
      "51.413094805666546\n",
      "50.89423880113204\n",
      "54.39360829449915\n",
      "49.92061593640407\n"
     ]
    }
   ],
   "source": [
    "print(len(average_0))\n",
    "print(len(average_1))\n",
    "print(np.mean(average_0))\n",
    "print(np.mean(average_1))\n",
    "print(np.std(average_0))\n",
    "print(np.std(average_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
